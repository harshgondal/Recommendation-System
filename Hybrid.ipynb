{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load and preprocess the data\n",
    "bid_df = pd.read_csv(r\"C:\\Users\\Harsh\\Desktop\\SheerDrive\\bid.csv\")\n",
    "auction_df = pd.read_csv(r\"C:\\Users\\Harsh\\Desktop\\SheerDrive\\auction.csv\")\n",
    "x = pd.read_csv(r\"C:\\Users\\Harsh\\Desktop\\SheerDrive\\merge.csv\")\n",
    "\n",
    "# Create a user-item matrix\n",
    "x = x.groupby(['buyer_id', 'make', 'model'])['bid_amount'].max().reset_index()\n",
    "user_item_matrix = x.pivot_table(\n",
    "    index='buyer_id',\n",
    "    columns=['make', 'model'],\n",
    "    values='bid_amount',\n",
    "    aggfunc='max'\n",
    ").fillna(0)\n",
    "\n",
    "# Calculate user similarities\n",
    "user_similarity = cosine_similarity(user_item_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "# Content-based filtering setup\n",
    "x['combined_features'] = x['make'] + \" \" + x['model']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(x['combined_features'].fillna(''))\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "indices = pd.Series(x.index, index=x['buyer_id']).drop_duplicates()\n",
    "\n",
    "# Content-based recommendation function\n",
    "def get_content_based_recommendations(buyer_id, df, cosine_sim, num_recommend=10):\n",
    "    # Check if the buyer_id exists in the indices\n",
    "    if buyer_id not in indices.index:\n",
    "        print(f\"No bids found for buyer_id {buyer_id}. Recommending based on overall popularity.\")\n",
    "        overall_popularity = df.groupby(['make', 'model'])['bid_amount'].mean().sort_values(ascending=False)\n",
    "        popular_cars = overall_popularity.head(num_recommend).reset_index()\n",
    "        return popular_cars[['make', 'model']]\n",
    "    \n",
    "    # Get the indices of cars the buyer has bid on\n",
    "    buyer_bids = df[df['buyer_id'] == buyer_id].index.tolist()\n",
    "    # Create a variable that contains make and model of the cars the buyer has previously bid on\n",
    "    previous_bids = df.loc[buyer_bids, ['make', 'model']].drop_duplicates().values.tolist()\n",
    "    previous_bids_set = set(map(tuple, previous_bids))  # Convert to set for faster lookup\n",
    "\n",
    "    # Calculate similarity scores for all cars\n",
    "    sim_scores = cosine_sim[buyer_bids].mean(axis=0)\n",
    "    # Get indices of cars sorted by similarity scores\n",
    "    similar_car_indices = sim_scores.argsort()[::-1]\n",
    "    # Ensure no repetitions in recommendations and filter out previously bid cars\n",
    "    unique_recommendations = []\n",
    "    seen = set()\n",
    "    \n",
    "    for idx in similar_car_indices:\n",
    "        car = (df.at[idx, 'make'], df.at[idx, 'model'])\n",
    "        if car not in seen and car not in previous_bids_set:\n",
    "            unique_recommendations.append(idx)\n",
    "            seen.add(car)\n",
    "        if len(unique_recommendations) == num_recommend:\n",
    "            break\n",
    "    \n",
    "    # Get recommended cars details\n",
    "    recommended_cars = df.iloc[unique_recommendations][['make', 'model']].drop_duplicates()\n",
    "    \n",
    "    return recommended_cars\n",
    "\n",
    "# Collaborative filtering prediction function\n",
    "def predict_interest(user_id, make, model, user_similarity_df, user_item_matrix):\n",
    "    if user_id not in user_similarity_df.index:\n",
    "        return 0\n",
    "    \n",
    "    similar_users = user_similarity_df[user_id].drop(user_id, errors='ignore')\n",
    "    similar_users = similar_users[similar_users > 0].sort_values(ascending=False)\n",
    "    \n",
    "    if similar_users.empty:\n",
    "        return 0\n",
    "    \n",
    "    weighted_sum = 0\n",
    "    similarity_sum = 0\n",
    "    for sim_user_id, similarity in similar_users.items():\n",
    "        if user_item_matrix.at[sim_user_id, (make, model)] > 0:\n",
    "            weighted_sum += similarity * user_item_matrix.at[sim_user_id, (make, model)]\n",
    "            similarity_sum += similarity\n",
    "    \n",
    "    if similarity_sum == 0:\n",
    "        return 0\n",
    "    \n",
    "    return weighted_sum / similarity_sum\n",
    "\n",
    "# Hybrid recommendation function\n",
    "def recommend_auctions(user_id, user_similarity_df, user_item_matrix, auction_df, cosine_sim, df, num_recommendations=5, cf_weight=0.7, cb_weight=0.3):\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        overall_popularity = user_item_matrix.mean(axis=0).sort_values(ascending=False)\n",
    "        recommended_auctions = overall_popularity.head(num_recommendations).index\n",
    "        return list(recommended_auctions), len(recommended_auctions)\n",
    "    \n",
    "    user_interactions = user_item_matrix.loc[user_id]\n",
    "    interacted_items = set(user_interactions[user_interactions > 0].index)\n",
    "    \n",
    "    predicted_interests_cf = {}\n",
    "    for (make, model) in user_item_matrix.columns:\n",
    "        if (make, model) not in interacted_items:\n",
    "            predicted_interests_cf[(make, model)] = predict_interest(user_id, make, model, user_similarity_df, user_item_matrix)\n",
    "    \n",
    "    recommended_auctions_cf = sorted(predicted_interests_cf.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    print(recommended_auctions_cf)\n",
    "    print(\"\\n\")\n",
    "    recommended_auctions_cb = get_content_based_recommendations(user_id, df, cosine_sim, num_recommend=num_recommendations)\n",
    "    print(recommended_auctions_cb)\n",
    "    \n",
    "    combined_scores = {}\n",
    "    \n",
    "    for (make, model), score in recommended_auctions_cf:\n",
    "        combined_scores[(make, model)] = cf_weight * score\n",
    "    \n",
    "    for _, row in recommended_auctions_cb.iterrows():\n",
    "        car = (row['make'], row['model'])\n",
    "        if car in combined_scores:\n",
    "            combined_scores[car] += cb_weight\n",
    "        else:\n",
    "            combined_scores[car] = cb_weight\n",
    "    \n",
    "    combined_recommendations = [(make, model) for (make, model), score in sorted(combined_scores.items(), key=lambda x: x[1], reverse=True) if (make, model) not in interacted_items]\n",
    "    \n",
    "    return combined_recommendations[:num_recommendations], len(combined_recommendations)\n",
    "\n",
    "# Example: Recommend auctions for buyer 333\n",
    "buyer_id = 134\n",
    "recommended_auction_details, num_recommendations = recommend_auctions(buyer_id, user_similarity_df, user_item_matrix, auction_df, cosine_sim, x, num_recommendations=5)\n",
    "print(f\"Recommended auctions: {recommended_auction_details}\")\n",
    "#print(f\"Number of recommendations: {num_recommendations}\")\n",
    "\n",
    "# Example: Recommend auctions for a new buyer (not in user_item_matrix)\n",
    "# new_buyer_id = 1  \n",
    "# recommended_auction_details, num_recommendations = recommend_auctions(new_buyer_id, user_similarity_df, user_item_matrix, auction_df, cosine_sim, x, num_recommendations=5)\n",
    "# print(f\"Recommended auctions for new buyer: {recommended_auction_details}\")\n",
    "# print(f\"Number of recommendations: {num_recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f401ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations have been saved to hybrid_recommendations_with_bids.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load and preprocess the data\n",
    "bid_df = pd.read_csv(r\"C:\\Users\\Harsh\\Desktop\\SheerDrive\\bid.csv\")\n",
    "auction_df = pd.read_csv(r\"C:\\Users\\Harsh\\Desktop\\SheerDrive\\auction.csv\")\n",
    "x = pd.read_csv(r\"C:\\Users\\Harsh\\Desktop\\SheerDrive\\merge.csv\")\n",
    "\n",
    "# Create a user-item matrix\n",
    "x = x.groupby(['buyer_id', 'make', 'model'])['bid_amount'].max().reset_index()\n",
    "user_item_matrix = x.pivot_table(\n",
    "    index='buyer_id',\n",
    "    columns=['make', 'model'],\n",
    "    values='bid_amount',\n",
    "    aggfunc='max'\n",
    ").fillna(0)\n",
    "\n",
    "# Calculate user similarities\n",
    "user_similarity = cosine_similarity(user_item_matrix)\n",
    "user_similarity_df = pd.DataFrame(user_similarity, index=user_item_matrix.index, columns=user_item_matrix.index)\n",
    "\n",
    "# Content-based filtering setup\n",
    "x['combined_features'] = x['make'] + \" \" + x['model']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(x['combined_features'].fillna(''))\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "indices = pd.Series(x.index, index=x['buyer_id']).drop_duplicates()\n",
    "\n",
    "# Content-based recommendation function\n",
    "def get_content_based_recommendations(buyer_id, df, cosine_sim, num_recommend=10):\n",
    "    # Check if the buyer_id exists in the indices\n",
    "    if buyer_id not in indices.index:\n",
    "        print(f\"No bids found for buyer_id {buyer_id}. Recommending based on overall popularity.\")\n",
    "        overall_popularity = df.groupby(['make', 'model'])['bid_amount'].mean().sort_values(ascending=False)\n",
    "        popular_cars = overall_popularity.head(num_recommend).reset_index()\n",
    "        return [], popular_cars[['make', 'model']].values.tolist()\n",
    "    \n",
    "    # Get the indices of cars the buyer has bid on\n",
    "    buyer_bids = df[df['buyer_id'] == buyer_id].index.tolist()\n",
    "    # Create a variable that contains make and model of the cars the buyer has previously bid on\n",
    "    previous_bids = df.loc[buyer_bids, ['make', 'model']].drop_duplicates().values.tolist()\n",
    "    previous_bids_set = set(map(tuple, previous_bids))  # Convert to set for faster lookup\n",
    "\n",
    "    # Calculate similarity scores for all cars\n",
    "    sim_scores = cosine_sim[buyer_bids].mean(axis=0)\n",
    "    # Get indices of cars sorted by similarity scores\n",
    "    similar_car_indices = sim_scores.argsort()[::-1]\n",
    "    # Ensure no repetitions in recommendations and filter out previously bid cars\n",
    "    unique_recommendations = []\n",
    "    seen = set()\n",
    "    \n",
    "    for idx in similar_car_indices:\n",
    "        car = (df.at[idx, 'make'], df.at[idx, 'model'])\n",
    "        if car not in seen and car not in previous_bids_set:\n",
    "            unique_recommendations.append(car)\n",
    "            seen.add(car)\n",
    "        if len(unique_recommendations) == num_recommend:\n",
    "            break\n",
    "    \n",
    "    return previous_bids, unique_recommendations\n",
    "\n",
    "# Collaborative filtering prediction function\n",
    "def predict_interest(user_id, make, model, user_similarity_df, user_item_matrix):\n",
    "    if user_id not in user_similarity_df.index:\n",
    "        return 0\n",
    "    \n",
    "    similar_users = user_similarity_df[user_id].drop(user_id, errors='ignore')\n",
    "    similar_users = similar_users[similar_users > 0].sort_values(ascending=False)\n",
    "    \n",
    "    if similar_users.empty:\n",
    "        return 0\n",
    "    \n",
    "    weighted_sum = 0\n",
    "    similarity_sum = 0\n",
    "    for sim_user_id, similarity in similar_users.items():\n",
    "        if user_item_matrix.at[sim_user_id, (make, model)] > 0:\n",
    "            weighted_sum += similarity * user_item_matrix.at[sim_user_id, (make, model)]\n",
    "            similarity_sum += similarity\n",
    "    \n",
    "    if similarity_sum == 0:\n",
    "        return 0\n",
    "    \n",
    "    return weighted_sum / similarity_sum\n",
    "\n",
    "# Hybrid recommendation function\n",
    "def recommend_auctions(user_id, user_similarity_df, user_item_matrix, auction_df, cosine_sim, df, num_recommendations=5, cf_weight=0.7, cb_weight=0.3):\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        overall_popularity = user_item_matrix.mean(axis=0).sort_values(ascending=False)\n",
    "        recommended_auctions = overall_popularity.head(num_recommendations).index\n",
    "        return [], list(recommended_auctions)\n",
    "    \n",
    "    user_interactions = user_item_matrix.loc[user_id]\n",
    "    interacted_items = set(user_interactions[user_interactions > 0].index)\n",
    "    \n",
    "    predicted_interests_cf = {}\n",
    "    for (make, model) in user_item_matrix.columns:\n",
    "        if (make, model) not in interacted_items:\n",
    "            predicted_interests_cf[(make, model)] = predict_interest(user_id, make, model, user_similarity_df, user_item_matrix)\n",
    "    \n",
    "    recommended_auctions_cf = sorted(predicted_interests_cf.items(), key=lambda x: x[1], reverse=True)[:num_recommendations]\n",
    "    recommended_auctions_cb = get_content_based_recommendations(user_id, df, cosine_sim, num_recommend=num_recommendations)[1]\n",
    "    \n",
    "    combined_scores = {}\n",
    "    \n",
    "    for (make, model), score in recommended_auctions_cf:\n",
    "        combined_scores[(make, model)] = cf_weight * score\n",
    "    \n",
    "    for make, model in recommended_auctions_cb:\n",
    "        if (make, model) in combined_scores:\n",
    "            combined_scores[(make, model)] += cb_weight\n",
    "        else:\n",
    "            combined_scores[(make, model)] = cb_weight\n",
    "    \n",
    "    combined_recommendations = [(make, model) for (make, model), score in sorted(combined_scores.items(), key=lambda x: x[1], reverse=True) if (make, model) not in interacted_items]\n",
    "    \n",
    "    previous_bids = [f\"{make} {model}\" for make, model in interacted_items]\n",
    "    \n",
    "    return previous_bids, combined_recommendations[:num_recommendations]\n",
    "\n",
    "# Generate recommendations for all buyers\n",
    "recommendations = []\n",
    "for buyer_id in x['buyer_id'].unique():\n",
    "    previously_bid_cars, recommended_cars = recommend_auctions(buyer_id, user_similarity_df, user_item_matrix, auction_df, cosine_sim, x, num_recommendations=5)\n",
    "    row = [buyer_id, previously_bid_cars] + recommended_cars\n",
    "    recommendations.append(row)\n",
    "\n",
    "# Determine the maximum number of recommendations\n",
    "max_recommendations = 5\n",
    "\n",
    "# Create column names\n",
    "columns = [\"buyer_id\", \"previously_bid\"] + [f\"Recommendation {i+1}\" for i in range(max_recommendations)]\n",
    "\n",
    "# Convert recommendations to DataFrame\n",
    "recommendations_df = pd.DataFrame(recommendations, columns=columns)\n",
    "\n",
    "# Save to Excel\n",
    "recommendations_df.to_excel(r\"C:\\Users\\Harsh\\Desktop\\hybrid.xlsx\", index=False)\n",
    "\n",
    "print(\"Recommendations have been saved to hybrid_recommendations_with_bids.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf079330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
